{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "49a9bba3-a609-4e82-9f75-1c95feab4a94",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing .............................Data processing finish.\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import re\n",
    "\n",
    "def clean_content(text):\n",
    "    # Replace accented characters and special cases\n",
    "    replacements = {\n",
    "        'á': 'a', 'é': 'e', 'í': 'i', 'ó': 'o', 'ú': 'u',\n",
    "        'Á': 'A', 'É': 'E', 'Í': 'I', 'Ó': 'O', 'Ú': 'U',\n",
    "        'ñ': 'n', 'Ñ': 'N', 'ü': 'u', 'Ü': 'U'\n",
    "    }\n",
    "    \n",
    "    # Replace each character in the dictionary\n",
    "    for accented_char, replacement_char in replacements.items():\n",
    "        text = text.replace(accented_char, replacement_char)\n",
    "    \n",
    "    # Remove references like [1], [ 99 ], etc.\n",
    "    text = re.sub(r'\\[\\s*[a-z0-9]*\\s*\\]', '', text)\n",
    "    \n",
    "    # Remove extra spaces\n",
    "    text = re.sub(r'\\s+', ' ', text)\n",
    "    \n",
    "    # Return cleaned text\n",
    "    return text.strip()\n",
    "    \n",
    "\n",
    "# URL de la página de Wikipedia\n",
    "url = \"https://en.wikipedia.org/wiki/Public_holidays_in_Puerto_Rico\"\n",
    "\n",
    "# Obtener el contenido HTML de la página\n",
    "response = requests.get(url)\n",
    "soup = BeautifulSoup(response.content, 'html.parser')\n",
    "\n",
    "print('Processing', end=' ')\n",
    "# Función para extraer y estructurar los datos de las tablas\n",
    "def extract_holidays(table, event, city_object, full_url, image_url):\n",
    "    holidays = []\n",
    "    rows = table.find_all(\"tr\")\n",
    "    \n",
    "    # Iterar por cada fila, excluyendo el encabezado\n",
    "    for row in rows[1:]:\n",
    "        print('.', end='')\n",
    "        cols = row.find_all(\"td\")\n",
    "        if len(cols) >= 4:  # Asegurarse de que la fila tenga las columnas necesarias\n",
    "            date = cols[0].get_text(strip=True)\n",
    "            english_name = clean_content(cols[1].get_text(strip=True))\n",
    "            local_name = clean_content(cols[2].get_text(strip=True))\n",
    "            remarks = clean_content(cols[3].get_text(strip=True))\n",
    "            \n",
    "            holiday_data = {\n",
    "                \"content\": remarks,\n",
    "                \"metadata\": {\n",
    "                    \"type\": 'event',\n",
    "                    \"city\": city_object[\"city\"],\n",
    "                    \"name\": english_name,\n",
    "                    \"categories\": [],\n",
    "                    'date': date,\n",
    "                    \"url\": full_url,\n",
    "                    \"image_url\": image_url\n",
    "                }\n",
    "            }\n",
    "            holidays.append(holiday_data)\n",
    "    return holidays\n",
    "\n",
    "# Datos generales\n",
    "city_object = {\"city\": \"Puerto Rico\"}\n",
    "full_url = url\n",
    "image_url = \"\"  # No se especificó ninguna imagen, así que queda vacío\n",
    "\n",
    "# Extraer ambas tablas (Official y Religious holidays)\n",
    "tables = soup.find_all(\"table\", {\"class\": \"wikitable\"})\n",
    "\n",
    "# Verificar si se encuentran las tablas necesarias\n",
    "official_holidays = extract_holidays(tables[0], \"Official public holidays\", city_object, full_url, image_url)\n",
    "religious_holidays = extract_holidays(tables[1], \"Religious holidays\", city_object, full_url, image_url)\n",
    "\n",
    "# Combinar los resultados y mostrar la salida\n",
    "all_holidays = official_holidays + religious_holidays\n",
    "\n",
    "# Imprimir los datos\n",
    "# for holiday in all_holidays:\n",
    "#     print(f'{holiday['content']}\\t{holiday['metadata']['city']}\\t{holiday['metadata']['name']}')\n",
    "\n",
    "print('Data processing finish.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68f2c6aa-0408-4e04-8680-ba6ea6b8de01",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "e53f2c38-0de5-45a7-b5b1-c70e4a720582",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data saved to puerto_rico_events.json\n"
     ]
    }
   ],
   "source": [
    "# Save the data into a JSON File\n",
    "with open('./datasets/puerto_rico_events.json', 'w') as file:\n",
    "    json.dump(all_holidays, file, indent=4)\n",
    "\n",
    "print('Data saved to puerto_rico_events.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a944d654-d61d-41f8-9d34-2c6a855b143a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (base)",
   "language": "python",
   "name": "base"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
